{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Icd6yirn0m4D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "X1_BOUND = np.pi/2.0\n",
        "X2_BOUND = 1.0\n",
        "X3_BOUND = 1.0\n",
        "U_BOUND = np.pi\n",
        "\n",
        "\n",
        "class SingleLinkManipulator(gym.Env):\n",
        "\n",
        "    # metadataã€€= {\n",
        "    #     \"render_modes\": [\"rgb_array\"]\n",
        "    # }\n",
        "\n",
        "    def __init__(self, N, B, M, Kb, R, L):\n",
        "        self.N = N\n",
        "        self.B = B\n",
        "        self.M = M\n",
        "        self.Kb = Kb\n",
        "        self.R = R\n",
        "        self.L = L\n",
        "        self.dt = 0.05\n",
        "        self.t = 0.0\n",
        "        self.x1 = 0.0\n",
        "        self.x2 = 0.0\n",
        "        self.x3 = 0.0\n",
        "\n",
        "        self.action_space = spaces.Box(\n",
        "            low=-U_BOUND, high=U_BOUND, dtype=np.float32, shape=(1,))\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([-X1_BOUND, -X2_BOUND, -X3_BOUND]),\n",
        "            high=np.array([X1_BOUND, X2_BOUND, X3_BOUND]),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def _signal(self):\n",
        "        # return (np.pi/2.0)*np.sin(8.0*np.pi*self.t/5.0)\n",
        "        return np.pi/3.0\n",
        "\n",
        "    def _get_obs(self):\n",
        "        return np.array([self.x1, self.x2, self.x3])\n",
        "\n",
        "    def _normalize_x1(self, x1):\n",
        "        x1 = x1 % np.pi\n",
        "        return x1 - (np.pi/2.0)\n",
        "\n",
        "    def step(self, u):\n",
        "        N = self.N\n",
        "        B = self.B\n",
        "        M = self.M\n",
        "        Kb = self.Kb\n",
        "        R = self.R\n",
        "        L = self.L\n",
        "        dt = self.dt\n",
        "\n",
        "        # clip action (voltage can't be negative)\n",
        "        u = np.clip(u, 0, U_BOUND)\n",
        "\n",
        "        # calculate update parameters\n",
        "        x1_dot = self.x2\n",
        "        x2_dot = -(N/M)*np.sin(self.x1) - (B/M)*self.x2 + (self.x3/M)\n",
        "        x3_dot = -(Kb/L)*self.x2 - (R/L)*self.x3 + (u/L)\n",
        "\n",
        "        # update parameters\n",
        "        # self.x1 = self._normalize_x1(self.x1 + x1_dot*dt)\n",
        "        self.x1 = np.clip(self.x1 + x1_dot*dt, -X1_BOUND, X1_BOUND)\n",
        "        self.x2 = np.clip(self.x2 + x2_dot*dt, -X2_BOUND, X2_BOUND)\n",
        "        self.x3 = np.clip(self.x3 + x3_dot*dt, 0, X3_BOUND)\n",
        "\n",
        "        self.t += dt\n",
        "\n",
        "        # calculate results\n",
        "        x1_expected = self._signal()\n",
        "        loss = (x1_expected - self.x1)**2 + self.x2**2 + self.x3**2\n",
        "\n",
        "        return self._get_obs(), -loss, False, False, {}\n",
        "\n",
        "    def reset(self, state=None):\n",
        "        self.t = 0\n",
        "        if state == None:\n",
        "            self.x1, self.x2, self.x3 = self.observation_space.sample()\n",
        "        else:\n",
        "            assert type(state) == type((0.0, 0.0, 0.0))\n",
        "            assert len(state) == 3\n",
        "            self.x1, self.x2, self.x3 = state\n",
        "        return self._get_obs(), {}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "# constants\n",
        "DISCRETIZATION_LEVEL = 50\n",
        "NEGINF = -1000000.0\n",
        "gamma = 0.99\n",
        "\n",
        "# state table values init\n",
        "X1 = np.linspace(-X1_BOUND, X1_BOUND, DISCRETIZATION_LEVEL)\n",
        "X2 = np.linspace(-X2_BOUND, X2_BOUND, DISCRETIZATION_LEVEL)\n",
        "X3 = np.linspace(0, X3_BOUND, DISCRETIZATION_LEVEL)\n",
        "N1 = X1.size\n",
        "N2 = X2.size\n",
        "N3 = X3.size\n",
        "\n",
        "# action space init\n",
        "U = np.linspace(0, U_BOUND, DISCRETIZATION_LEVEL)\n",
        "\n",
        "# optimal policy and value init\n",
        "policy = np.zeros((N1, N2, N3))\n",
        "V = np.full((N1, N2, N3), 0.0)\n",
        "nextV = np.full((U.size), 0.0)\n",
        "\n",
        "# parameter init\n",
        "J = 1.625103\n",
        "m = 0.506\n",
        "M0 = 0.434\n",
        "L0 = 0.305\n",
        "R0 = 0.023\n",
        "B0 = 16.25163\n",
        "L = 25.0103\n",
        "R = 5.0\n",
        "Kt = Kb = 0.90\n",
        "g = 9.8\n",
        "M = J + m*L0*L0/3.0 + M0*L0*L0 + 2*M0*R0*R0/5/Kt\n",
        "N = m*L0*g/2.0 + M0*L0*g/Kt\n",
        "B = B0/Kt\n",
        "\n",
        "\n",
        "# initialize env\n",
        "env = SingleLinkManipulator(N, B, M, Kb, R, L)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48k6haWj3ppk",
        "outputId": "dbc539af-b71c-4ab3-d85e-288497318a94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_nearest(array, value):\n",
        "    idx = np.searchsorted(array, value, side=\"left\")\n",
        "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
        "        return idx-1\n",
        "    else:\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "Nszx_qch3xp4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(100):\n",
        "    for i in range(N1):\n",
        "        for j in range(N2):\n",
        "            for k in range(N3):\n",
        "                state = (X1[i], X2[j], X3[k])\n",
        "                for u in range(U.size):\n",
        "                    env.reset(state)\n",
        "                    new_state, _, _, _, _ = env.step(U[u])\n",
        "                    x1, x2, x3 = new_state\n",
        "                    x1 = find_nearest(X1, x1)\n",
        "                    x2 = find_nearest(X2, x2)\n",
        "                    x3 = find_nearest(X3, x3)\n",
        "                    nextV[u] = V[x1, x2, x3]\n",
        "                Vbest = np.max(nextV)\n",
        "                reward = -(env._signal() - X1[i])**2\n",
        "                V[i, j, k] = reward + gamma*Vbest\n"
      ],
      "metadata": {
        "id": "VIWxJP9z3y73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(N1):\n",
        "    for j in range(N2):\n",
        "        for k in range(N3):\n",
        "            state = (X1[i], X2[j], X3[k])\n",
        "            env.reset(state)\n",
        "            for u in range(U.size):\n",
        "                new_state, _, _, _, _ = env.step(U[u])\n",
        "                x1, x2, x3 = new_state\n",
        "                x1 = find_nearest(X1, x1)\n",
        "                x2 = find_nearest(X2, x2)\n",
        "                x3 = find_nearest(X3, x3)\n",
        "                nextV[u] = V[x1, x2, x3]\n",
        "            Vbest_idx = np.argmax(nextV)\n",
        "            policy[i, j, k] = U[Vbest_idx]\n"
      ],
      "metadata": {
        "id": "1FoaigGB32D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(3,)),\n",
        "    keras.layers.Dense(10, activation='softplus'),\n",
        "    keras.layers.Dense(10, activation='softplus'),\n",
        "    keras.layers.Dense(1, activation='relu'),\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.MeanSquaredError()],\n",
        ")\n",
        "\n",
        "x_train = np.array([[0,0,0]])\n",
        "y_train = np.array([0])\n",
        "\n",
        "for i in range(N1):\n",
        "    for j in range(N2):\n",
        "        for k in range(N3):\n",
        "            x_train = np.append(x_train, [[i, j, k]], axis=0)\n",
        "            y_train = np.append(y_train, policy[i, j, k])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        ")\n"
      ],
      "metadata": {
        "id": "E1rKjL-x33fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "rewards = np.array([])\n",
        "for eps in range(200):\n",
        "    state = env._get_obs()\n",
        "    # print(state)\n",
        "    # print(state.shape)\n",
        "    print(np.atleast_2d(state).shape)\n",
        "    action = model.predict((np.atleast_2d(state)).astype(np.float32))[0][0]\n",
        "    # print(action.shape)\n",
        "    _ ,reward, _,_,_ = env.step(action)\n",
        "    rewards = np.append(rewards, reward)\n",
        "\n",
        "plt.plot(rewards) "
      ],
      "metadata": {
        "id": "rwkG8wDk36Pi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}